C was designed to write the Unix operating system in a time of irregular architectures.  Its durability and staying power is a testament to its level of abstraction from any specific hardware, yet its ability to program closely to all.

Go is a modern programming language intended to be fast where C is fast in spite of a garbage collector.\cite{Go}  It has the look and feel of a higher level language without the cost of an interpreter.  It has lambdas, message passing, array slices, and a host of other features not commonly associated with systems languages.  However, even though it's able to eliminate array bounds checking in most cases, it still checks unless it can prove it doesn't have to.  Additionally, Go types always respect alignment, even within structures, so a programmer can reorder the members but there is no way to pack it down to the machine-addressable level.  Quite apart from that, whereas, in C, programmers weigh the tradeoffs of allocating objects on the stack versus the heap, Go's allocations are defined by the implementation.

In Rust the story is a little better. Although the default padding and alignment are unspecified and Rust even reserves the right to reorder members, Rust has compiler directives dictating memory layout like that in C and to pack structures.

C++, building on C, is designed neither to introduce safety-related overheads, nor to prohibit programmer fine-tuning to architectural peculiarities.  It doesn't, for example, insert instructions to protect programmers from invalid array indexes.  In fact, memory allocators implemented in C++ depend on the ability to do exactly that, often storing memory metadata in a structure before the memory handed out.\cite{Hoard, TCMalloc, Supermalloc}  As in C, memory is memory, and any type structure can be imposed upon it.

Control over memory layout is crucial to concurrent data structures since fetching cache lines, especially unpredictably, can saturate memory bandwidth quickly.  And \textit{false sharing}, wherein one thread writes to a memory address sharing cache line with a different memory address being viewed by another thread, leads to slow down by inadvertant cache invalidation.  Memory layout needs to be predictable and controllable in a language that's close to the machine.

Control over code generation, both in the knowledge that no unexpected ``safety'' instructions will be generated, and the ability to generate specific instructions, is the other dimension of a close to the machine language, as C and C++ do in their respective ways with \textit{read-modify-write} atomics.  The C11 standard, for example, added intrinsic functions for RMW operations.\cite{C11Atomics}

DEF necessarily includes control over memory layout, and disincludes runtime safety checks that might slow down operations.  It also provides an \texttt{atomic} annotation for operations that should be RMW, and intrinsics for more specific semantics and non-binary instructions.
